- hosts: localhost
  become: yes

  tasks:
    - name: Create a security group for the Kubernetes Master Node
      amazon.aws.ec2_security_group:
        name: kubernetes-master-node
        description: Kubernetes Master Node security group.
        region: us-east-1
        vpc_id: vpc-04e0a7049e32e9957
        rules:
          - proto: tcp
            from_port: 80
            to_port: 80
            cidr_ip: 0.0.0.0/0
          - proto: tcp
            from_port: 22
            to_port: 22
            # for production usecases, only limit the SSH port to be accessible to a specific number of IPs
            cidr_ip: 0.0.0.0/0 
          # define an inbound rule to expose port 5000
          - proto: tcp
            from_port: 5000
            to_port: 5000
            cidr_ip: 0.0.0.0/0
           # port for Docker API Access 
          - proto: tcp
            from_port: 2375
            to_port: 2375
            cidr_ip: 0.0.0.0/0
          # For Kubernetes API server
          - proto: tcp
            from_port: 6443
            to_port: 6443
            cidr_ip: 0.0.0.0/0
          - proto: tcp
            from_port: 8080
            to_port: 8080
            cidr_ip: 0.0.0.0/0
          # For etcd server client API
          - proto: tcp
            from_port: 2379
            to_port: 2380
            cidr_ip: 0.0.0.0/0
          # For Kubelet API
          - proto: tcp
            from_port: 10250
            to_port: 10250
            cidr_ip: 0.0.0.0/0
          # For kube-scheduler
          - proto: tcp
            from_port: 10259
            to_port: 10259
            cidr_ip: 0.0.0.0/0
          # For kube-controller-manager
          - proto: tcp
            from_port: 10257
            to_port: 10257
            cidr_ip: 0.0.0.0/0
          # Cluster-Wide Network Comm. — Flannel VXLAN
          - proto: udp
            from_port: 8472
            to_port: 8472
            cidr_ip: 0.0.0.0/0
        rules_egress:
          - proto: all
            cidr_ip: 0.0.0.0/0
      register: kubernetes_master_node_security_group
    - name: Create a security group for the Kubernetes Worker Node
      amazon.aws.ec2_security_group:
        name: kubernetes-worker-node
        description: Kubernetes Worker Node security group.
        region: us-east-1
        vpc_id: vpc-04e0a7049e32e9957
        rules:
          - proto: tcp
            from_port: 80
            to_port: 80
            cidr_ip: 0.0.0.0/0
          - proto: tcp
            from_port: 22
            to_port: 22
            # for production usecases, only limit the SSH port to be accessible to a specific number of IPs
            cidr_ip: 0.0.0.0/0 
          # define an inbound rule to expose port 5000
          - proto: tcp
            from_port: 5000
            to_port: 5000
            cidr_ip: 0.0.0.0/0
           # port for Docker API Access 
          - proto: tcp
            from_port: 2375
            to_port: 2375
            cidr_ip: 0.0.0.0/0
          # For For Kubelet API
          - proto: tcp
            from_port: 10250
            to_port: 10250
            cidr_ip: 0.0.0.0/0
          - proto: all # tpc
            from_port: 8080
            to_port: 8080
            cidr_ip: 0.0.0.0/0
          # For NodePort Services†
          - proto: tcp
            from_port: 30000
            to_port: 32767
            cidr_ip: 0.0.0.0/0
          # Cluster-Wide Network Comm. — Flannel VXLAN
          - proto: udp
            from_port: 8472
            to_port: 8472
            cidr_ip: 0.0.0.0/0
        rules_egress:
          - proto: all
            cidr_ip: 0.0.0.0/0
      register: kubernetes_worker_node_security_group
    - name: Create Kubernetes Master Node EC2 Instance
      amazon.aws.ec2_instance:
        name: kubernetes-master-node
        region: us-east-1
        key_name: ansible--to-manage-remote-machines
        instance_type: t2.medium # Satisfies at least 2 CPU Core and 2GB RAM requirement
        security_group: kubernetes-master-node
        vpc_subnet_id: subnet-0565633e9a42bd845
        state: running
        network:
          assign_public_ip: true
          delete_on_termination: true
        image_id: ami-053b0d53c279acc90
      register: kubernetes_master_node
    - name: Create Kubernetes Worker Node EC2 Instance
      amazon.aws.ec2_instance:
        name: kubernetes-worker-node
        region: us-east-1
        key_name: ansible--to-manage-remote-machines
        instance_type: t2.medium # Satisfies at least 2 CPU Core and 2GB RAM requirement
        security_group: kubernetes-worker-node
        vpc_subnet_id: subnet-0565633e9a42bd845
        state: running
        network:
          assign_public_ip: true
          delete_on_termination: true
        image_id: ami-053b0d53c279acc90
      register: kubernetes_worker_node
    - name: Set Master Node's Private Ip Address
      set_fact:
        master_node_private_ip: "{{ kubernetes_master_node.instances[0].network_interfaces[0].private_ip_address }}"
    - name: Print public ip address for the master node
      debug:
        var: kubernetes_master_node.instances[0].network_interfaces[0].association.public_ip
    - name: Ping the master node
      ping:
        data: "{{ kubernetes_master_node.instances[0].network_interfaces[0].association.public_ip }}"
    - name: Print public ip address for worker node
      debug:
        var: kubernetes_worker_node.instances[0].network_interfaces[0].association.public_ip
    - name: Ping the worker node
      ping:
        data: "{{ kubernetes_worker_node.instances[0].network_interfaces[0].association.public_ip }}"
    - name: Add the Kubernetes Master Node to the Ansible inventory
      add_host:
        name:  "{{ kubernetes_master_node.instances[0].network_interfaces[0].association.public_ip }}"
        groups: master
    - name: Add the Kubernetes Worker Node to the Ansible inventory
      add_host:
        name:  "{{ kubernetes_worker_node.instances[0].network_interfaces[0].association.public_ip }}"
        groups: worker


- hosts: master
  become: yes
  tasks: 
  - name: Set a master hostname
    ansible.builtin.hostname:
      name: master
  - name: Update package repositories
    apt:
      update_cache: yes
  - name: Install required system packages
    apt:
      pkg:
        - apt-transport-https
        - curl
        - gnupg2
      state: latest
  - name: Add Docker GPG apt Key
    apt_key:
      url: 'https://download.docker.com/linux/ubuntu/gpg'
      state: present
  - name: Add Docker Repository
    apt_repository:
      repo: deb https://download.docker.com/linux/ubuntu focal stable
      state: present
  - name: Install Docker
    apt:
      name: docker.io
      state: present
  - name: Add the ansible user to the docker group
    user:
      name: "{{ ansible_user }}" # initially --> the name: root
      groups: docker
      append: yes
  - name: Restart Docker service
    service:
      name: docker
      state: restarted
  - name: Add Kubernetes apt-key
    apt_key:
      url: https://packages.cloud.google.com/apt/doc/apt-key.gpg
      state: present
  - name: Add Kubernetes repository
    apt_repository:
      repo: deb https://apt.kubernetes.io/ kubernetes-xenial main
      state: present
  - name: Install Kubernetes components
    apt:
      update_cache: yes
      name:
        - kubelet
        - kubeadm
        - kubectl
        - kubernetes-cni 
      state: present
  - name: Update the `iptables` of Linux Nodes to enable them to see bridged traffic correctly
    copy:
      content: |
        net.bridge.bridge-nf-call-ip6tables = 1
        net.bridge.bridge-nf-call-iptables = 1
      dest: /etc/sysctl.d/k8s.conf
      owner: root
      group: root
      mode: '0644'
  - name: Load sysctl settings
    sysctl:
      name: net.bridge.bridge-nf-call-ip6tables
      value: '1'
      sysctl_set: yes
    become: yes
  - name: Load sysctl settings
    sysctl:
      name: net.bridge.bridge-nf-call-ip6tables
      value: '1'
      sysctl_set: yes
    become: yes
  - name: Pull kubernetes container images
    ansible.builtin.command: kubeadm config images pull
  - name: Configure Docker cgroup driver - Create /etc/docker/daemon.json file
    copy:
        content: '{"exec-opts": ["native.cgroupdriver=systemd"]}'
        dest: /etc/docker/daemon.json
  - name: Configure Docker cgroup driver - Reload systemd daemon
    systemd:
        daemon_reexec: yes
        name: docker
        state: reloaded
  - name: Configure Docker cgroup driver - Restart Docker service
    systemd:
      name: docker
      state: restarted
  - name: Configure Docker cgroup driver - Restart kubelet service
    systemd:
      name: kubelet
      state: restarted
  - name: Set Master Node's Private Ip Address
    set_fact:
      master_node_private_ip: hostvars['localhost'].master_node_private_ip
  - name: Print private ip address for the master node
    debug:
      var: "{{ master_node_private_ip }}"
  - name: Execute kubeadm reset
    command: 
      cmd: kubeadm reset --force
  - name: Initialize Kubernetes master node
    shell: kubeadm init --apiserver-advertise-address="{{hostvars['localhost'].master_node_private_ip}}" --pod-network-cidr=10.244.0.0/16
    register: kubeadm_output
  - name: Display kubeadm output
    debug:
      var: kubeadm_output.stdout_lines
  # Set join command variable to be used by worker nodes to join the cluster
  - name: Set join command variable to be used by worker nodes to join the cluster
    set_fact:
      join_command: "{{ kubeadm_output.stdout_lines[-2:] }}"
  - name: Display the join command
    debug:
      var: join_command
  - name: Setup kubeconfig on master node - Create .kube directory
    file:
      path: /root/.kube
      state: directory
  - name: Setup kubeconfig on master node - Copy admin.conf to kubeconfig
    copy:
      src: /etc/kubernetes/admin.conf
      dest: /root/.kube/config"
      remote_src: yes
      mode: '0644'
  - name: Setup kubeconfig on master node - Set ownership for kubeconfig
    file:
      path: /root/.kube/config"
      owner: root
      group: root
      mode: '0644'
  - name: Stop kubelet service
    service:
      name: kubelet
      state: stopped
  - name: Start kubelet service
    service:
      name: kubelet
      state: started
  - name: Run strace on kubectl version command
    command:
      cmd: strace -eopenat kubectl version
  - name: Activate Flannel pod networking
    shell: kubectl apply -f https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml
    args:
      executable: /bin/bash
  - name: Run kubectl get nodes
    command: kubectl get nodes
    register: kubectl_output
  - name: Display kubectl output
    debug:
      var: kubectl_output.stdout_lines


- hosts: worker
  become: yes
  tasks: 
  - name: Set a worker hostname
    ansible.builtin.hostname:
      name: worker
  - name: Update package repositories
    apt:
      update_cache: yes
  - name: Install required system packages
    apt:
      pkg:
        - apt-transport-https
        - curl
        - gnupg2
      state: latest
  - name: Add Docker GPG apt Key
    apt_key:
      url: 'https://download.docker.com/linux/ubuntu/gpg'
      state: present
  - name: Add Docker Repository
    apt_repository:
      repo: deb https://download.docker.com/linux/ubuntu focal stable
      state: present
  - name: Install Docker
    apt:
      name: docker.io
      state: present
  - name: Add the ansible user to the docker group
    user:
      name: "{{ ansible_user }}" # initially --> the name: root
      groups: docker
      append: yes
  - name: Restart Docker service
    service:
      name: docker
      state: restarted
  - name: Add Kubernetes apt-key
    apt_key:
      url: https://packages.cloud.google.com/apt/doc/apt-key.gpg
      state: present
  - name: Add Kubernetes repository
    apt_repository:
      repo: deb https://apt.kubernetes.io/ kubernetes-xenial main
      state: present
  - name: Install Kubernetes components
    apt:
      update_cache: yes
      name:
        - kubelet
        - kubeadm
        - kubectl
        - kubernetes-cni 
      state: present
  - name: Update the `iptables` of Linux Nodes to enable them to see bridged traffic correctly
    copy:
      content: |
        net.bridge.bridge-nf-call-ip6tables = 1
        net.bridge.bridge-nf-call-iptables = 1
      dest: /etc/sysctl.d/k8s.conf
      owner: root
      group: root
      mode: '0644'
  - name: Load sysctl settings
    sysctl:
      name: net.bridge.bridge-nf-call-ip6tables
      value: '1'
      sysctl_set: yes
    become: yes
  - name: Load sysctl settings
    sysctl:
      name: net.bridge.bridge-nf-call-ip6tables
      value: '1'
      sysctl_set: yes
    become: yes
  - name: Configure Docker cgroup driver - Create /etc/docker/daemon.json file
    copy:
        content: '{"exec-opts": ["native.cgroupdriver=systemd"]}'
        dest: /etc/docker/daemon.json
  - name: Configure Docker cgroup driver - Reload systemd daemon
    systemd:
        daemon_reexec: yes
        name: docker
        state: reloaded
  - name: Configure Docker cgroup driver - Restart Docker service
    systemd:
      name: docker
      state: restarted
  - name: Configure Docker cgroup driver - Restart kubelet service
    systemd:
      name: kubelet
      state: restarted
  - name: Join the worker node to the cluster
    command: sudo join_command
  - name: Download Helm installation script
    get_url:
      url: https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3
      dest: /tmp/get-helm-3
  - name: Run Helm installation script
    command: bash /tmp/get-helm-3
  - name: Deploy the app using helm
    command:
        cmd: helm install greetings deploy/charts/greetings